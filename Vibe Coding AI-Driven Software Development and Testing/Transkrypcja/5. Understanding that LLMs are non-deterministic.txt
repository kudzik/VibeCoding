5. Understanding that LLMs are non-deterministic

Behind the scenes.

Most tools like cursor use something which is called an agent.

You can think of an agent like a smart helper that can take actions.

For example, working with files, running commands in a terminal, writing code, fixing bugs, and

even interact with external tools.

But here's the catch the agent can do so much on its own.

It needs to be connected to something more powerful.

A large language model.

And that is the brain behind the scenes.

The LLM is what actually understands your words and generates responses, writes the code, which then

the AI transforms into the project.

In this lecture, I want to point out something very important about this large language models, and

that is the fact that they are non-deterministic.

So what do I mean by that?

Well, it means that if you give the same input or prompt, you can still get a different answer each

time.

Throughout the course I'm going to provide you the prompts that I use.

But you're going to see that what you're getting back is slightly different.

But why does it happen?

Imagine asking the same question to a human three times.

You will not get the exact same words each time, right?

And this is how llms work.

Also, they are not robots that only say the same thing.

They are a bit like people, a bit creative, a bit random.

And this can happen for a few reasons.

One of these reasons is something called temperature, which is a setting that controls how creative

the model can be.

A higher temperature makes it more random.

A lower one makes it more focused and predictable, which is generally good for writing code.

While this is a key concept in AI, most tools don't expose this as a setting, so don't go looking

for it.

But I think it's still important to know about it.

Apart from the setting, each large language model has its own personality if you want to call it like

that, because it has its own training, data and design.

So even if we send the same prompt to two different models that are tuned, let's say, with the same

temperature.

For example, when answering that question, they will still give different responses and quite often

they will be quite, quite different.

But no, this small randomness that we're getting is still helpful.

It can give us fresh ideas, alternative solutions, and can help us explore different ways of solving

a problem.

So this is something to keep in mind if you're not happy with the result that you're getting with the

first try, you can just delete everything and start from scratch and get a different solution and see

if you like that better.

It's just rolling the dice once again.

So this is just a heads up before we move on.

You might try the same prompt I'm showing on the screen and get slightly different results or totally

different results.

And this is absolutely normal.

It doesn't mean anything is broken, it is just how these tools work.

You just need to continue the chat based on the response you get.

Each conversation is slightly different.
